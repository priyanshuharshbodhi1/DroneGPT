{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cb4159-6e95-4d7d-9a94-bfb0ca81f9d6",
   "metadata": {},
   "source": [
    "# 1 AirSim Simulation and OpenAI gpt-oss Development Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a71a127-b1ef-4fcb-a2cc-bc3217a3cd75",
   "metadata": {},
   "source": [
    "## Introduction to AirSim\n",
    "\n",
    "AirSim (Aerial Informatics and Robotics Simulation) is an open-source robotics simulation platform developed by Microsoft Research, primarily used for algorithm development and testing of autonomous systems such as drones and self-driving cars. The following introduces AirSim from three aspects: core functionalities, technical features, and application scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### I. Core Functionalities\n",
    "\n",
    "1. **Multi-modal Simulation Support**  \n",
    "   AirSim supports the simulation of various types of vehicles, including drones, ground vehicles, and static IoT devices, providing a high-fidelity physical and visual simulation environment. Its built-in sensor models (e.g., IMU, GPS, cameras, LiDAR) can generate data that closely resembles real-world conditions, suitable for training and validating AI models.\n",
    "\n",
    "2. **Hardware-in-the-Loop and Software-in-the-Loop Simulation**  \n",
    "   The platform supports integration with flight controllers such as PX4 and ArduPilot, enabling Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) simulations. This allows developers to combine real hardware with virtual environments for testing.\n",
    "\n",
    "3. **Data Generation and Debugging Tools**  \n",
    "   AirSim can efficiently generate large-scale training data and simulate high-risk scenarios such as collisions and complex weather conditions to reduce the cost of real-world testing. For example, simulating drone crashes incurs almost no cost but provides valuable information for improving designs.\n",
    "\n",
    "---\n",
    "\n",
    "### II. Technical Features\n",
    "\n",
    "1. **Realistic Rendering Based on Unreal Engine**  \n",
    "   As a plugin for Unreal Engine, AirSim leverages the engine's physics computation and graphics rendering capabilities to create highly realistic 3D scenes (e.g., cities, mountains, indoor environments), making it ideal for developing vision-dependent navigation algorithms.\n",
    "\n",
    "2. **Modular Design and Cross-platform Compatibility**  \n",
    "   With a modular architecture, AirSim supports the extension of hardware and algorithm interfaces, and is compatible with both Windows and Linux systems. It enables flexible control through Python and C++ APIs, as well as ROS/ROS2 interfaces.\n",
    "\n",
    "3. **Multi-drone Cooperative Simulation**  \n",
    "   By configuring files, multiple drones can be simulated simultaneously, supporting distributed control and verification of complex tasks (e.g., formation flying), meeting the needs of research and education.\n",
    "\n",
    "---\n",
    "\n",
    "### III. Application Scenarios\n",
    "\n",
    "- **Autonomous Driving Algorithm Development**: Simulate vehicle perception and decision-making in complex traffic conditions to accelerate deep learning model training.\n",
    "- **Drone Obstacle Avoidance and Path Planning**: Test SLAM and autonomous navigation algorithms in GPS-denied environments (e.g., inside buildings).\n",
    "- **Education and Research**: Provide a low-cost experimental platform for robotics education and reinforcement learning research.\n",
    "\n",
    "---\n",
    "\n",
    "### Current Status and Development\n",
    "\n",
    "As of 2025, the official open-source version of AirSim has ceased updates and has been archived, although users can still access the historical codebase.\n",
    "\n",
    "However, several teams continue to develop and improve upon AirSim, such as:\n",
    "- [Cosys-AirSim](https://github.com/Cosys-Lab/Cosys-AirSim): Adds more sensors and upgrades to Unreal Engine 5.\n",
    "- [Colosseum](https://github.com/CodexLabsLLC/Colosseum): Optimizes deployment workflows by adapting to Windows systems and Unreal Engine 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e9115-b575-4204-bdaf-a0ec4a04cb18",
   "metadata": {},
   "source": [
    "### AirSim Simulation\n",
    "\n",
    "The simulation environment used in the paper *\"ChatGPT for Robotics: Design Principles and Model Abilities\"*\n",
    "\n",
    "You can download it directly from its GitHub page:  \n",
    "https://github.com/microsoft/PromptCraft-Robotics/releases/tag/1.0.0\n",
    "\n",
    "After downloading and extracting the files, you can run the simulation directly:\n",
    "\n",
    "<img src=\"img/airsim1-1.jpg\" width='600px' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9098acf-c4c0-425f-b1f7-86c24b76bb70",
   "metadata": {},
   "source": [
    "## AirSim Related Documentation\n",
    "\n",
    "AirSim [GitHub](https://github.com/microsoft/airsim/releases)\n",
    "\n",
    "AirSim [Documentation](https://microsoft.github.io/AirSim/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863b148-4bc9-457b-afcb-2eec0c8119f5",
   "metadata": {},
   "source": [
    "## Introduction to OpenAI gpt-oss\n",
    "\n",
    "**gpt-oss** represents OpenAI's breakthrough open-weight reasoning models, specifically designed for complex problem-solving and multi-step reasoning tasks. These models excel at spatial reasoning, safety analysis, and autonomous decision-making - making them ideal for robotics applications.\n",
    "\n",
    "### Key Capabilities\n",
    "\n",
    "- **Advanced Spatial Reasoning**: gpt-oss can understand and reason about 3D environments, making it perfect for drone navigation and obstacle avoidance\n",
    "- **Multi-step Mission Planning**: The model can break down complex tasks into sequential steps with safety considerations\n",
    "- **Reasoning Effort Control**: Dynamic intelligence scaling with low/medium/high reasoning effort based on task complexity\n",
    "- **Safety-First Analysis**: Built-in risk assessment and emergency protocol generation\n",
    "\n",
    "### Technical Features\n",
    "\n",
    "- **Open Weight Models**: Full model weights available for research and development\n",
    "- **HuggingFace Integration**: Easy deployment through HuggingFace's Inference API\n",
    "- **Real-time Processing**: Optimized for robotics applications requiring quick decision-making\n",
    "- **Scalable Reasoning**: Adaptive computational load based on reasoning complexity\n",
    "\n",
    "### Application in Robotics\n",
    "\n",
    "gpt-oss transforms traditional command-execution robotics into intelligent reasoning systems:\n",
    "- **Natural Language Control**: Convert plain English instructions into safe robotic actions\n",
    "- **Environmental Analysis**: Assess risks and plan optimal paths in real-time\n",
    "- **Mission Adaptation**: Dynamically adjust plans based on changing conditions\n",
    "- **Safety Protocols**: Generate and execute emergency procedures autonomously\n",
    "\n",
    "### Why gpt-oss for Drones?\n",
    "\n",
    "Unlike traditional LLMs that simply generate text responses, gpt-oss provides genuine reasoning capabilities essential for autonomous systems:\n",
    "- **Spatial Understanding**: Comprehends 3D coordinates, distances, and navigation constraints\n",
    "- **Risk Assessment**: Evaluates safety margins before executing potentially dangerous maneuvers\n",
    "- **Context Awareness**: Maintains understanding of mission objectives while adapting to obstacles\n",
    "- **Explanation Generation**: Provides clear reasoning for decisions, crucial for debugging and safety validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74493ee2-efbb-48a8-997e-058d5ad7c600",
   "metadata": {},
   "source": [
    "## OpenAI gpt-oss via HuggingFace\n",
    "\n",
    "The reasoning model service used in this project is **OpenAI gpt-oss** accessed through HuggingFace's Inference API.\n",
    "\n",
    "### Setup Instructions:\n",
    "\n",
    "1. **Get HuggingFace Token**: Visit [HuggingFace Settings](https://huggingface.co/settings/tokens)\n",
    "2. **Create Token**: Generate a new token with \"Inference Providers\" permission\n",
    "3. **Configure Environment**: Set `HF_TOKEN` in your `.env` file\n",
    "\n",
    "### Model Access:\n",
    "\n",
    "```python\n",
    "# Example HuggingFace API configuration for gpt-oss\n",
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    model=\"openai/gpt-oss\",  # OpenAI's open reasoning model\n",
    "    token=os.getenv(\"HF_TOKEN\")\n",
    ")\n",
    "```\n",
    "\n",
    "### Integration with DroneGPT:\n",
    "\n",
    "Update the `HF_TOKEN` in your `.env` file:\n",
    "```\n",
    "HF_TOKEN=your_huggingface_token_here\n",
    "```\n",
    "\n",
    "The reasoning models will be automatically loaded in `airsim_agent.py` and `tello_agent.py` for intelligent drone control.\n",
    "\n",
    "### Reasoning Effort Control:\n",
    "\n",
    "gpt-oss supports dynamic reasoning effort scaling:\n",
    "- **Low Effort**: Quick responses for basic maneuvers (takeoff, land, simple movements)\n",
    "- **Medium Effort**: Navigation planning and obstacle avoidance\n",
    "- **High Effort**: Complex mission analysis and safety protocol generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a4a71-e5e1-42b7-b509-b1d259550d61",
   "metadata": {},
   "source": [
    "### Python Environment\n",
    "\n",
    "**Requirements:**\n",
    "- Python == 3.10\n",
    "- HuggingFace Hub\n",
    "- Transformers\n",
    "- AirSim Python API\n",
    "- DJI Tello SDK\n",
    "\n",
    "**Recommended Setup:**\n",
    "- Conda + Jupyter Lab\n",
    "- GPU support for faster inference (optional)\n",
    "\n",
    "**Installation:**\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3cdea1-3102-428d-a99d-ffa39e67d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
